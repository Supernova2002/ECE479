{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fml_lib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as ss\n",
    "import os.path\n",
    "from math import sqrt, exp, log\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dstek\\AppData\\Local\\Temp\\ipykernel_30648\\1907931566.py:1: FutureWarning: Support for nested sequences for 'parse_dates' in pd.read_csv is deprecated. Combine the desired columns with pd.to_datetime after parsing instead.\n",
      "  dollar_bars = pd.read_csv(\"USA500IDXUSD_bars.csv\", parse_dates=[['Date', 'Timestamp']])\n"
     ]
    }
   ],
   "source": [
    "dollar_bars = pd.read_csv(\"USA500IDXUSD_bars.csv\", parse_dates=[['Date', 'Timestamp']])\n",
    "dollar_bars = dollar_bars.set_index(\"Date_Timestamp\")\n",
    "close = dollar_bars['Close']\n",
    "daily_volatility = fml_lib.getDailyVol(dollar_bars.Close,span0=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if os.path.exists(\"./t_events.csv\"):\n",
    "    t_events = pd.read_csv(\"t_events.csv\", index_col=[0])\n",
    "    t_events = t_events.index\n",
    "else:\n",
    "    t_events = fml_lib.getTEvents(dollar_bars.Close, daily_volatility)\n",
    "    t_events_df = pd.DataFrame(index= t_events)\n",
    "    t_events_df.to_csv(\"./t_events_csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2023-07-04 22:00:10', '2023-07-04 22:00:40',\n",
      "               '2023-07-04 22:00:50', '2023-07-04 22:01:10',\n",
      "               '2023-07-04 22:01:30', '2023-07-04 22:01:50',\n",
      "               '2023-07-04 22:02:10', '2023-07-04 22:02:20',\n",
      "               '2023-07-04 22:02:40', '2023-07-04 22:03:00',\n",
      "               ...\n",
      "               '2024-01-25 03:52:20', '2024-01-25 03:53:40',\n",
      "               '2024-01-25 03:54:50', '2024-01-25 03:55:10',\n",
      "               '2024-01-25 03:55:40', '2024-01-25 03:56:50',\n",
      "               '2024-01-25 03:57:00', '2024-01-25 03:57:20',\n",
      "               '2024-01-25 03:58:30', '2024-01-25 03:58:40'],\n",
      "              dtype='datetime64[ns]', length=814094, freq=None)\n"
     ]
    }
   ],
   "source": [
    "t_events = pd.to_datetime(t_events)\n",
    "print(t_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-04 22:00:10   2023-07-16 22:00:00\n",
      "2023-07-04 22:00:40   2023-07-16 22:00:00\n",
      "2023-07-04 22:00:50   2023-07-16 22:00:00\n",
      "2023-07-04 22:01:10   2023-07-16 22:00:00\n",
      "2023-07-04 22:01:30   2023-07-16 22:00:00\n",
      "                              ...        \n",
      "2024-01-15 03:54:40   2024-01-25 03:54:50\n",
      "2024-01-15 03:56:00   2024-01-25 03:56:50\n",
      "2024-01-15 03:57:00   2024-01-25 03:57:00\n",
      "2024-01-15 03:57:30   2024-01-25 03:58:30\n",
      "2024-01-15 03:58:40   2024-01-25 03:58:40\n",
      "Name: Date_Timestamp, Length: 769572, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#adds the vertical barrier num_days out from the time of the event\n",
    "numDays = 10\n",
    "t1=close.index.searchsorted(t_events+pd.Timedelta(days=numDays))\n",
    "t1=t1[t1<close.shape[0]]\n",
    "t1=pd.Series(close.index[t1],index=t_events[:t1.shape[0]]) # NaNs at end\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      t1  trgt\n",
      "2023-07-04 22:00:10  2023-07-04 22:17:50  0.01\n",
      "2023-07-04 22:00:40  2023-07-04 22:17:50  0.01\n",
      "2023-07-04 22:00:50  2023-07-04 22:15:30  0.01\n",
      "2023-07-04 22:01:10  2023-07-04 22:17:50  0.01\n",
      "2023-07-04 22:01:30  2023-07-04 22:17:50  0.01\n",
      "...                                  ...   ...\n",
      "2024-01-25 03:50:30  2024-01-25 03:56:50  0.01\n",
      "2024-01-25 03:51:30  2024-01-25 03:54:50  0.01\n",
      "2024-01-25 03:51:40  2024-01-25 03:56:50  0.01\n",
      "2024-01-25 03:51:50  2024-01-25 03:54:50  0.01\n",
      "2024-01-25 03:52:00  2024-01-25 03:56:50  0.01\n",
      "\n",
      "[814081 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "min_ret= 0.005\n",
    "trgt = pd.Series(0.01, index=t_events)\n",
    "if os.path.exists(\"./events.csv\"):\n",
    "    events = pd.read_csv(\"events.csv\", index_col=[0])\n",
    "    events = events.dropna()\n",
    "else:\n",
    "    events = fml_lib.getEvents(close, t_events, 0.02,trgt ,min_ret,t1)\n",
    "    events.to_csv(\"events.csv\")\n",
    "print(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True ...  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "bins = fml_lib.getBins(events, close, numDays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          ret  bin\n",
      "2023-07-04 22:02:10 -0.000225 -1.0\n",
      "2023-07-04 22:02:40 -0.000223 -1.0\n",
      "2023-07-04 22:03:00 -0.000223 -1.0\n",
      "2023-07-04 22:03:10 -0.000210 -1.0\n",
      "2023-07-04 22:13:00 -0.000222 -1.0\n",
      "...                       ...  ...\n",
      "2024-01-25 03:40:30 -0.000205 -1.0\n",
      "2024-01-25 03:40:40 -0.000207 -1.0\n",
      "2024-01-25 03:40:50 -0.000210 -1.0\n",
      "2024-01-25 03:41:10 -0.000207 -1.0\n",
      "2024-01-25 03:41:40 -0.000209 -1.0\n",
      "\n",
      "[401614 rows x 2 columns]\n",
      "                          ret  bin\n",
      "2023-07-04 22:00:10  0.000226  1.0\n",
      "2023-07-04 22:00:40  0.000223  1.0\n",
      "2023-07-04 22:00:50  0.000220  1.0\n",
      "2023-07-04 22:01:10  0.000226  1.0\n",
      "2023-07-04 22:01:30  0.000224  1.0\n",
      "...                       ...  ...\n",
      "2024-01-25 03:50:30  0.000207  1.0\n",
      "2024-01-25 03:51:30  0.000216  1.0\n",
      "2024-01-25 03:51:40  0.000208  1.0\n",
      "2024-01-25 03:51:50  0.000215  1.0\n",
      "2024-01-25 03:52:00  0.000207  1.0\n",
      "\n",
      "[814081 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(bins[bins['bin'] == -1])\n",
    "print(bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Want to find sample weights for use in the boosting fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m co_events \u001b[38;5;241m=\u001b[39m \u001b[43mfml_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_co_events\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclose\u001b[49m\u001b[43m,\u001b[49m\u001b[43mevents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(co_events)\n",
      "File \u001b[1;32mc:\\Users\\dstek\\Documents\\ECE479\\fml_lib.py:588\u001b[0m, in \u001b[0;36mget_co_events\u001b[1;34m(close, t1)\u001b[0m\n\u001b[0;32m    586\u001b[0m             overlap_series\u001b[38;5;241m.\u001b[39mappend(unique_count)\n\u001b[0;32m    587\u001b[0m     last_index \u001b[38;5;241m=\u001b[39m index\n\u001b[1;32m--> 588\u001b[0m overlap_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43moverlap_series\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    589\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m overlap_df\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\reshape\\concat.py:380\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    378\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 380\u001b[0m op \u001b[38;5;241m=\u001b[39m \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    393\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\reshape\\concat.py:443\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    440\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverify_integrity \u001b[38;5;241m=\u001b[39m verify_integrity\n\u001b[0;32m    441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;241m=\u001b[39m copy\n\u001b[1;32m--> 443\u001b[0m objs, keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_clean_keys_and_objs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;66;03m# figure out what our result ndim is going to be\u001b[39;00m\n\u001b[0;32m    446\u001b[0m ndims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_ndims(objs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\reshape\\concat.py:505\u001b[0m, in \u001b[0;36m_Concatenator._clean_keys_and_objs\u001b[1;34m(self, objs, keys)\u001b[0m\n\u001b[0;32m    502\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(objs)\n\u001b[0;32m    504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs_list) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 505\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo objects to concatenate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    507\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    508\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(com\u001b[38;5;241m.\u001b[39mnot_none(\u001b[38;5;241m*\u001b[39mobjs_list))\n",
      "\u001b[1;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "co_events = fml_lib.get_co_events(close,events)\n",
    "print(co_events)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
